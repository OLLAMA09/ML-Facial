# -*- coding: utf-8 -*-
"""
FacialMLCode.py

Facial attribute recognition workflow using CelebA dataset and ResNet18.
Automatically generated by Colab, refactored for clarity and best practices.
"""

import os
import shutil
import time
import zipfile
import pandas as pd
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms, models
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Kaggle API authentication and download (not shown for brevity)

# Paths
DATA_DIR = '/content/celeba_images/'
IMG_DIR = os.path.join(DATA_DIR, 'img_align_celeba')
ATTR_FILE = os.path.join(DATA_DIR, 'list_attr_celeba.csv')

# Load attributes
def load_attributes(attr_file):
    df = pd.read_csv(attr_file)
    if 'image_id' not in df.columns:
        df.rename(columns={df.columns[0]: 'image_id'}, inplace=True)
    df.set_index('image_id', inplace=True)
    for col in df.columns:
        df[col] = df[col].replace(-1, 0)
    return df

df_attributes = load_attributes(ATTR_FILE)

# Verify images
assert os.path.exists(IMG_DIR)
assert len(os.listdir(IMG_DIR)) > 0

# Visual check
def show_sample_images(df, img_dir, sample_size=5):
    sample_ids = df.index[:sample_size]
    plt.figure(figsize=(15, 3))
    for i, img_id in enumerate(sample_ids):
        img_path = os.path.join(img_dir, img_id)
        try:
            img = Image.open(img_path).convert('RGB')
            plt.subplot(1, sample_size, i + 1)
            plt.imshow(img)
            plt.title(f"Image ID: {img_id}")
            plt.axis('off')
        except Exception as e:
            plt.subplot(1, sample_size, i + 1)
            plt.text(0.5, 0.5, f"Error\n{img_id}", ha='center', va='center', color='red')
            plt.axis('off')
    plt.tight_layout()
    plt.show()

show_sample_images(df_attributes, IMG_DIR)

# PyTorch transforms
image_size = 64
transform = transforms.Compose([
    transforms.Resize((image_size, image_size)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Custom Dataset
class CelebADataset(Dataset):
    def __init__(self, df, img_dir, transform=None):
        self.df = df.copy()
        self.img_dir = img_dir
        self.transform = transform
        self.image_filenames = self.df.index.tolist()

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        img_name = self.image_filenames[idx]
        img_path = os.path.join(self.img_dir, img_name)
        image = Image.open(img_path).convert('RGB')
        attributes = self.df.loc[img_name].values.astype(np.float32)
        attributes_tensor = torch.from_numpy(attributes)
        if self.transform:
            image = self.transform(image)
        return image, attributes_tensor

# Split PyTorch dataset
total_size = len(df_attributes)
train_size = int(0.6 * total_size)
val_size = int(0.2 * total_size)
test_size = total_size - train_size - val_size

celeba_dataset = CelebADataset(df_attributes, IMG_DIR, transform=transform)
train_dataset, val_dataset, test_dataset = random_split(
    celeba_dataset,
    [train_size, val_size, test_size],
    generator=torch.Generator().manual_seed(42)
)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)

# Model: Pretrained ResNet18 for multi-label classification
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_attributes = df_attributes.shape[1]
model = models.resnet18(pretrained=True)
model.fc = torch.nn.Sequential(
    torch.nn.Linear(model.fc.in_features, num_attributes),
    torch.nn.Sigmoid()
)
model = model.to(device)

# Training loop
criterion = torch.nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)
num_epochs = 6

train_losses, val_losses, val_accuracies = [], [], []

for epoch in range(num_epochs):
    model.train()
    running_train_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item() * images.size(0)
    epoch_train_loss = running_train_loss / len(train_loader.dataset)
    train_losses.append(epoch_train_loss)

    # Validation
    model.eval()
    running_val_loss = 0.0
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            running_val_loss += loss.item() * images.size(0)
            preds = (outputs > 0.5).float()
            correct += (preds == labels).sum().item()
            total += np.prod(labels.shape)
    epoch_val_loss = running_val_loss / len(val_loader.dataset)
    val_losses.append(epoch_val_loss)
    val_accuracies.append(correct / total)

    print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val Acc: {val_accuracies[-1]:.4f}")

# Plot losses and accuracy
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.legend()
plt.title("Loss Curves")

plt.subplot(1,2,2)
plt.plot(val_accuracies, label="Val Accuracy")
plt.legend()
plt.title("Validation Accuracy")
plt.show()

# Test set evaluation
model.eval()
correct, total = 0, 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        preds = (outputs > 0.5).float()
        correct += (preds == labels).sum().item()
        total += np.prod(labels.shape)
test_accuracy = correct / total
print(f"Test set accuracy (per-attribute): {test_accuracy:.4f}")

# Save model
torch.save(model.state_dict(), "celeba_resnet18_multilabel.pth")
print("Model checkpoint saved as celeba_resnet18_multilabel.pth")

# Keras/TensorFlow pipeline (for reference)
target_attributes = ['Smiling', 'Male', 'Young', 'Wearing_Lipstick']
df_for_training = df_attributes.reset_index()
df_for_training['filepath'] = df_for_training['image_id'].apply(lambda x: os.path.join(IMG_DIR, x))
df_for_training = df_for_training[df_for_training['filepath'].apply(os.path.exists)]
sample_df = df_for_training.sample(n=10000, random_state=42)
train_df, val_df = train_test_split(sample_df, test_size=0.2, random_state=42)

image_size = (128, 128)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col='filepath',
    y_col=target_attributes,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='raw',
    seed=42
)
validation_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col='filepath',
    y_col=target_attributes,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='raw',
    seed=42
)
````We're waiting for your response to the push dialog; once you accept, your README and refactored code will be uploaded to your repository.
